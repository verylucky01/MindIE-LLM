# README

# ç‰¹æ€§çŸ©é˜µ
- æ­¤çŸ©é˜µç½—åˆ—äº†å„å‘é‡åŒ–æ¨¡å‹æ”¯æŒçš„ç‰¹æ€§

| æ¨¡å‹åŠå‚æ•°é‡             | 800I A2 Tensor Parallelism | 300I DUO Tensor Parallelism | FP16 | BF16 | Flash Attention | Paged Attention | W8A8é‡åŒ– | W8A16é‡åŒ– | KV cacheé‡åŒ– | ç¨€ç–é‡åŒ– | MOEé‡åŒ– | MindIE Service | TGI | é•¿åºåˆ— |
|--------------------|----------------------------|-----------------------------|------|------|-----------------|-----------------|--------|---------|------------|------|-------|----------------|-----|-----|
| bge-large-zh-v1.5  | æ”¯æŒworld size 1             | æ”¯æŒworld size 1              | âˆš    | Ã—    | âˆš               | Ã—               | Ã—      | Ã—       | Ã—          | Ã—    | Ã—     | Ã—              | Ã—   | Ã—   |
| bge-reranker-large | æ”¯æŒworld size 1             | æ”¯æŒworld size 1              | âˆš    | Ã—    | âˆš               | Ã—               | Ã—      | Ã—       | Ã—          | Ã—    | Ã—     | Ã—              | Ã—   | Ã—   |
| bge-m3             | æ”¯æŒworld size 1             | æ”¯æŒworld size 1              | âˆš    | Ã—    | âˆš               | Ã—               | Ã—      | Ã—       | Ã—          | Ã—    | Ã—     | Ã—              | Ã—   | Ã—   |
| Conan-embedding-v1 | æ”¯æŒworld size 1             | æ”¯æŒworld size 1              | âˆš    | Ã—    | âˆš               | Ã—               | Ã—      | Ã—       | Ã—          | Ã—    | Ã—     | Ã—              | Ã—   | Ã—   |
| puff-large-v1      | æ”¯æŒworld size 1             | æ”¯æŒworld size 1              | âˆš    | Ã—    | âˆš               | Ã—               | Ã—      | Ã—       | Ã—          | Ã—    | Ã—     | Ã—              | Ã—   | Ã—   |

# å‘é‡åŒ–æ¨¡å‹-æ¨ç†æŒ‡å¯¼

<!-- TOC -->
* [README](#readme)
* [ç‰¹æ€§çŸ©é˜µ](#ç‰¹æ€§çŸ©é˜µ)
* [å‘é‡åŒ–æ¨¡å‹-æ¨ç†æŒ‡å¯¼](#å‘é‡åŒ–æ¨¡å‹-æ¨ç†æŒ‡å¯¼)
  * [æ¦‚è¿°](#æ¦‚è¿°)
    * [æ¨¡å‹ä»‹ç»](#æ¨¡å‹ä»‹ç»)
    * [å¼€æºæƒé‡](#å¼€æºæƒé‡)
    * [è·¯å¾„å˜é‡](#è·¯å¾„å˜é‡)
  * [æ¨ç†ç¯å¢ƒå‡†å¤‡](#æ¨ç†ç¯å¢ƒå‡†å¤‡)
  * [å¿«é€Ÿä¸Šæ‰‹](#å¿«é€Ÿä¸Šæ‰‹)
    * [è·å–æœ¬é¡¹ç›®æºç ](#è·å–æœ¬é¡¹ç›®æºç )
    * [å®‰è£…ä¾èµ–](#å®‰è£…ä¾èµ–)
    * [è·å–å¼€æºæ¨¡å‹æƒé‡](#è·å–å¼€æºæ¨¡å‹æƒé‡)
    * [è·å–æµ‹è¯•æ•°æ®é›†](#è·å–æµ‹è¯•æ•°æ®é›†)
  * [æ¨¡å‹æ¨ç†](#æ¨¡å‹æ¨ç†)
  * [æ¨¡å‹æ¨ç†æ€§èƒ½&ç²¾åº¦](#æ¨¡å‹æ¨ç†æ€§èƒ½ç²¾åº¦)
<!-- TOC -->

## æ¦‚è¿°

### æ¨¡å‹ä»‹ç»

å‘é‡åŒ–æ¨¡å‹æ˜¯å¯å°†ä»»æ„æ–‡æœ¬æ˜ å°„ä¸ºä½ç»´ç¨ å¯†å‘é‡çš„è¯­è¨€æ¨¡å‹ï¼Œä»¥ç”¨äºæ£€ç´¢ã€åˆ†ç±»ã€èšç±»æˆ–è¯­ä¹‰åŒ¹é…ç­‰ä»»åŠ¡ï¼Œå¹¶å¯æ”¯æŒä¸ºå¤§æ¨¡å‹è°ƒç”¨å¤–éƒ¨çŸ¥è¯†  
æœ¬é¡¹ç›®æ”¯æŒ `BERT` åŠ `XLMRoBERTa` ä¸¤ç§ç»“æ„ã€ `embedding` åŠ `rerank` ä¸¤ç§å‘é‡åŒ–ç±»å‹çš„æ¨¡å‹

> ğŸ’¡ **å¦‚ä½•ç¡®è®¤æ¨¡å‹çš„ç»“æ„å’Œå‘é‡åŒ–ç±»å‹ï¼Ÿ**  
> æ¨¡å‹æƒé‡ç›®å½•ä¸­çš„ `config.json` æ–‡ä»¶é…ç½®äº†æ¨¡å‹çš„ç»“æ„å’Œå‘é‡åŒ–ç±»å‹ï¼Œ`"model_type"` çš„å€¼è¡¨ç¤ºäº†æ¨¡å‹ç»“æ„ï¼Œ`"architectures"` çš„å€¼è¡¨ç¤ºäº†æ¨¡å‹çš„å‘é‡åŒ–ç±»å‹ï¼ˆ`*Model` è¡¨ç¤ºæ˜¯ `embedding`ï¼Œ`*ForSequenceClassification` è¡¨ç¤ºæ˜¯ `rerank`ï¼‰

### å¼€æºæƒé‡

[bge-large-zh-v1.5](https://huggingface.co/BAAI/bge-large-zh-v1.5/tree/main)  
[bge-reranker-large](https://huggingface.co/BAAI/bge-reranker-large/tree/main)  
[bge-m3](https://huggingface.co/BAAI/bge-m3/tree/main)  
[Conan-embedding-v1](https://huggingface.co/TencentBAC/Conan-embedding-v1/tree/main)  
[puff-large-v1](https://huggingface.co/infgrad/puff-large-v1/tree/main)

### è·¯å¾„å˜é‡

**è·¯å¾„å˜é‡è§£é‡Š**

| å˜é‡å            | å«ä¹‰                                                                                                                            |
|----------------|-------------------------------------------------------------------------------------------------------------------------------|
| `working_dir`  | åŠ é€Ÿåº“åŠæ¨¡å‹åº“ä¸‹è½½åæ”¾ç½®çš„ç›®å½•                                                                                                               |
| `llm_path`     | æ¨¡å‹ä»“æ‰€åœ¨è·¯å¾„<br/>è‹¥ä½¿ç”¨ç¼–è¯‘å¥½çš„åŒ…ï¼Œåˆ™è·¯å¾„ä¸º `${working_dir}/MindIE-LLM/`<br/>è‹¥ä½¿ç”¨gitcodeä¸‹è½½çš„ä»£ç ï¼Œåˆ™è·¯å¾„ä¸º `${working_dir}/MindIE-LLM/examples/atb_models` |
| `script_path`  | è„šæœ¬æ‰€åœ¨è·¯å¾„<br/>å‘é‡åŒ–æ¨¡å‹çš„è„šæœ¬æ‰€åœ¨è·¯å¾„ä¸º `${llm_path}/examples/models/embedding`                                                              |
| `weight_path`  | æ¨¡å‹æƒé‡æ‰€åœ¨è·¯å¾„                                                                                                                      |
| `dataset_path` | æ•°æ®é›†æ‰€åœ¨è·¯å¾„                                                                                                                       |

## æ¨ç†ç¯å¢ƒå‡†å¤‡

- å‚è€ƒ[atb_modelsçš„READMEæ–‡ä»¶](../../../README.md)é…ç½®å¥½æ¨ç†ç¯å¢ƒ
- è®¾ç½®ç¯å¢ƒå˜é‡
    ```shell
    source /usr/local/Ascend/cann/set_env.sh
    ```
- å®‰è£…ç›¸å…³Pythonåº“
    ```shell
    cd ${script_path}
    pip install -r requirements.txt
    ```

## å¿«é€Ÿä¸Šæ‰‹

### è·å–æœ¬é¡¹ç›®æºç 
    
```shell
cd ${working_dir}
git clone https://gitcode.com/ascend/MindIE-LLM.git
cd MindIE-LLM
git checkout master
```

### è·å–å¼€æºæ¨¡å‹æƒé‡

ç‚¹å‡»[å¼€æºæƒé‡](#å¼€æºæƒé‡)ä¸­çš„é“¾æ¥ï¼Œä¸‹è½½ğŸ¤—HuggingFaceæ¨¡å‹å®˜æ–¹é¡µé¢ä¸­çš„æ‰€æœ‰æ–‡ä»¶è‡³ `${weight_path}` ç›®å½•

> âš ï¸ å¦‚æœæ¨¡å‹åˆ†è¯å™¨é…ç½®æ–‡ä»¶ `${weight_path}/tokenizer_config.json` ä¸­çš„ `model_max_length` çš„å€¼ä¸ºç±»ä¼¼ `1e30` ç­‰çš„è¶…å¤§æ•°å€¼ï¼Œéœ€è¦ä¿®æ”¹å…¶ä¸º `${weight_path}/config.json` ä¸­çš„ `max_position_embeddings` çš„å€¼

### è·å–æµ‹è¯•æ•°æ®é›†

- `embedding` æ¨¡å‹ä½¿ç”¨ `T2Retrieval` æ•°æ®é›†ï¼Œè¯¥æ•°æ®é›†åŒ…å«ä¸¤éƒ¨åˆ†ï¼Œéœ€è¦åˆ†åˆ«ä¸‹è½½  
    [T2Retrieval](https://huggingface.co/datasets/C-MTEB/T2Retrieval/tree/main)  
    [T2Retrieval-qrels](https://huggingface.co/datasets/C-MTEB/T2Retrieval-qrels/tree/main)
- `rerank` æ¨¡å‹ä½¿ç”¨ `T2Reranking`æ•°æ®é›†  
    [T2Reranking](https://huggingface.co/datasets/C-MTEB/T2Reranking/tree/main)

æ•°æ®é›†ä¸‹è½½åæ”¾åœ¨ `${dataset_path}` ç›®å½•ä¸­ï¼Œå¹¶ç¡®ä¿ä¸‹è½½çš„æ¯ä¸ªæ•°æ®é›†éƒ½æ‹¥æœ‰ç‹¬ç«‹çš„å­ç›®å½•ï¼Œä¾‹å¦‚

```
${dataset_path}
â”œâ”€â”€ T2Reranking
â”‚   â””â”€â”€ data
â”‚       â””â”€â”€ dev-00000-of-00001-65d96bde8023d9b9.parquet
â”œâ”€â”€ T2Retrieval
â”‚   â””â”€â”€ data
â”‚       â”œâ”€â”€ corpus-00000-of-00001-8afe7b7a7eca49e3.parquet
â”‚       â””â”€â”€ queries-00000-of-00001-930bf3b805a80dd9.parquet
â””â”€â”€ T2Retrieval-qrels
    â””â”€â”€ data
        â””â”€â”€ dev-00000-of-00001-92ed0416056ff7e1.parquet
```

## æ¨¡å‹æ¨ç†

æ‰“å¼€ç®—å­è°ƒåº¦ä¾§åŒçº¿ç¨‹

```shell
export ATB_OPERATION_EXECUTE_ASYNC=1
export TASK_QUEUE_ENABLE=1
```

1. ä½¿ç”¨ç¤ºä¾‹è„šæœ¬æ¨ç†

    ```shell
    cd ${script_path}
    python run.py \
      ${request} \
      --model_name_or_path ${weight_path} \
      --device_type ${device_type} \
      --device_id ${device_id} \
      --text ${text} \
      (--nonpadding)
    ```

    - å‚æ•°è¯´æ˜
      - `request`ï¼šæ‰§è¡Œçš„æ¨ç†ä»»åŠ¡
        - `embedding` æ¨¡å‹è¾“å…¥ `embed`
        - `rerank` æ¨¡å‹è¾“å…¥ `rerank`
      - `weight_path`ï¼šæ¨¡å‹ç±»å‹æˆ–æ¨¡å‹æ–‡ä»¶è·¯å¾„
      - `device_type`ï¼šåŠ è½½æ¨¡å‹çš„èŠ¯ç‰‡ç±»å‹
      - `device_id`ï¼šåŠ è½½æ¨¡å‹çš„èŠ¯ç‰‡id
      - `text`ï¼šè¾“å…¥æ¨¡å‹æ¨ç†è®¡ç®—å‘é‡çš„æ–‡æœ¬
        - `embedding` æ¨¡å‹å¯è¾“å…¥å¤šæ¡æ–‡æœ¬ï¼Œæ–‡æœ¬ç”¨å¼•å· `"` åŒ…è£¹ï¼Œæ–‡æœ¬ä¹‹é—´ç”¨ç©ºæ ¼ ` ` åˆ†éš”ï¼Œå¦‚ `"ä»€ä¹ˆæ˜¯å¤§ç†ŠçŒ«" "å±äºé£Ÿè‚‰ç›®ç†Šç§‘çš„ä¸€ç§å“ºä¹³åŠ¨ç‰©" "æ˜¯ä¸€ç§å°å‹çŠ¬å“ç§"`
        - `rerank` æ¨¡å‹å¯è¾“å…¥å¤šæ¡æ–‡æœ¬å¯¹ï¼Œæ–‡æœ¬å¯¹ç”¨å¼•å· `"` åŒ…è£¹ï¼Œæ–‡æœ¬å¯¹ä¹‹é—´ç”¨ç©ºæ ¼ ` ` åˆ†éš”ï¼Œæ–‡æœ¬å¯¹ä¸­çš„æ–‡æœ¬ç”¨ `|` åˆ†éš”ï¼Œå¦‚ `"ä»€ä¹ˆæ˜¯å¤§ç†ŠçŒ«|å±äºé£Ÿè‚‰ç›®ç†Šç§‘çš„ä¸€ç§å“ºä¹³åŠ¨ç‰©" "ä»€ä¹ˆæ˜¯å¤§ç†ŠçŒ«|æ˜¯ä¸€ç§å°å‹çŠ¬å“ç§"`
      - `nonpadding`ï¼šå¯é€‰è®¾ç½®ï¼Œå¼€å¯åˆè½´è¾“å…¥çš„ `batch_size` å’Œ `seq_len` ç»´åº¦
        - å®éªŒæ€§åŠŸèƒ½
        - ä¸è®¾ç½®æ­¤é¡¹åˆ™ä¸å¼€å¯åˆè½´ï¼Œé»˜è®¤ä¸å¼€å¯åˆè½´ï¼Œè®¾ç½®æ­¤é¡¹åˆ™å¼€å¯åˆè½´

2. ä½¿ç”¨ğŸ¤—HuggingFace Transformerså¹¶è‡ªå·±ç¼–å†™è„šæœ¬æ¨ç†

    > ğŸ’¡ å¯å‚è€ƒå…·ä½“æ¨¡å‹å®˜æ–¹é¡µé¢ä¸­çš„æ¨ç†ç¤ºä¾‹

    ```python
    import torch
    from transformers import AutoConfig, AutoTokenizer
    from model_runner import get_model_from_pretrained
    
    # è¾“å…¥æ¨ç†æ–‡æœ¬
    sentences = ["æ ·ä¾‹æ•°æ®-1", "æ ·ä¾‹æ•°æ®-2"]
    
    # ä»æœ¬åœ°è·¯å¾„åŠ è½½åˆ†è¯å™¨å’Œæƒé‡
    # âš ï¸é‡è¦ï¼š`trust_remote_code` å‚æ•°éœ€è¦è®¾ä¸º `True`
    config = AutoConfig.from_pretrained(weight_path, trust_remote_code=True)
    tokenizer = AutoTokenizer.from_pretrained(weight_path, trust_remote_code=True)
    model = get_model_from_pretrained(
        config,
        "AutoModel",  # ä¸‹æ¸¸ä»»åŠ¡å¯¹åº”çš„ Auto Class
        weight_path
    )
    model.to("npu").eval()
    
    # æ¨¡å‹æ¨ç†
    encoded_input = tokenizer(sentences, padding=True, truncation=True, return_tensors="pt")
    with torch.no_grad():
        model_output = model(**encoded_input, return_dict=True)
    
    # ä¸‹æ¸¸ä»»åŠ¡ï¼Œæ ¹æ®è‡ªå·±éœ€æ±‚ä¿®æ”¹
    sentence_embeddings = torch.nn.functional.normalize(model_output[0][:, 0], p=2, dim=1).cpu()
    ```

## æ¨¡å‹æ¨ç†æ€§èƒ½&ç²¾åº¦

æ‰“å¼€ç®—å­è°ƒåº¦ä¾§åŒçº¿ç¨‹

```shell
export ATB_OPERATION_EXECUTE_ASYNC=1
export TASK_QUEUE_ENABLE=1
```

1. æ€§èƒ½æµ‹è¯•

    > ååç‡è®¡ç®—å…¬å¼ï¼š$1000 \times \frac{batch\_size}{compute\_time}$

    å…³é—­ç¡®å®šæ€§è®¡ç®—ï¼Œå¯ä»¥æå‡æ€§èƒ½

    ```shell
    export LCCL_DETERMINISTIC=0
    export HCCL_DETERMINISTIC=false
    ```

    ```shell
    cd ${script_path}
    python test.py \
      performance \
      --model_name_or_path ${weight_path} \
      --device_type ${device_type} \
      --device_id ${device_id} \
      --batch_size ${batch_size} \
      --max_seq_len ${seq_len} \
      --loop ${loop} \
      --outputs ${outputs} \
      (--nonpadding)
    ```
    
    - å‚æ•°è¯´æ˜
      - `weight_path`ï¼šæ¨¡å‹ç±»å‹æˆ–æ¨¡å‹æ–‡ä»¶è·¯å¾„
      - `device_type`ï¼šåŠ è½½æ¨¡å‹çš„èŠ¯ç‰‡ç±»å‹
      - `device_id`ï¼šåŠ è½½æ¨¡å‹çš„èŠ¯ç‰‡id
      - `batch_size`ï¼šæ¯è½®æ¨ç†çš„æ–‡æœ¬æ‰¹æ¬¡
      - `seq_len`ï¼šæ¯è½®æ¨ç†çš„æ–‡æœ¬é•¿åº¦
      - `loop`ï¼šæµ‹è¯•çš„å¾ªç¯æ¬¡æ•°ï¼Œéœ€è¦æ˜¯æ­£æ•´æ•°
      - `outputs`ï¼šæµ‹è¯•ç»“æœçš„ä¿å­˜è·¯å¾„
      - `nonpadding`ï¼šå¯é€‰è®¾ç½®ï¼Œå¼€å¯åˆè½´è¾“å…¥çš„ `batch_size` å’Œ `seq_len` ç»´åº¦
        - å®éªŒæ€§åŠŸèƒ½
        - ä¸è®¾ç½®æ­¤é¡¹åˆ™ä¸å¼€å¯åˆè½´ï¼Œé»˜è®¤ä¸å¼€å¯åˆè½´ï¼Œè®¾ç½®æ­¤é¡¹åˆ™å¼€å¯åˆè½´

2. ç²¾åº¦æµ‹è¯•

    æ‰“å¼€ç¡®å®šæ€§è®¡ç®—ï¼Œä¿è¯å¤šæ¬¡æµ‹è¯•ç»“æœä¸€è‡´

    ```shell
    export LCCL_DETERMINISTIC=1
    export HCCL_DETERMINISTIC=true
    ```

    ```shell
    cd ${script_path}
    python test.py \
      ${task} \
      --model_name_or_path ${weight_path} \
      --device_type ${device_type} \
      --device_id ${device_id} \
      --dataset_path ${dataset_path} \
      --batch_size ${batch_size} \
      --outputs ${outputs} \
      (--nonpadding)
    ```
    
    - å‚æ•°è¯´æ˜
      - `task`ï¼šç²¾åº¦æµ‹è¯•ä»»åŠ¡
        - `embedding` æ¨¡å‹è¾“å…¥ `retrieval`
        - `rerank` æ¨¡å‹è¾“å…¥ `reranking`
      - `weight_path`ï¼šæ¨¡å‹ç±»å‹æˆ–æ¨¡å‹æ–‡ä»¶è·¯å¾„
      - `device_type`ï¼šåŠ è½½æ¨¡å‹çš„èŠ¯ç‰‡ç±»å‹
      - `device_id`ï¼šåŠ è½½æ¨¡å‹çš„èŠ¯ç‰‡id
      - `dataset_path`ï¼šæ•°æ®é›†åœ°å€ï¼Œ`embedding` æ¨¡å‹çš„ç²¾åº¦æµ‹è¯•åªéœ€è¦è¾“å…¥ `T2Retrieval` æ•°æ®é›†çš„è·¯å¾„
      - `batch_size`ï¼šæ¯è½®æ¨ç†çš„æ–‡æœ¬æ‰¹æ¬¡
      - `outputs`ï¼šæµ‹è¯•ç»“æœçš„ä¿å­˜è·¯å¾„
      - `nonpadding`ï¼šå¯é€‰è®¾ç½®ï¼Œå¼€å¯åˆè½´è¾“å…¥çš„ `batch_size` å’Œ `seq_len` ç»´åº¦
        - å®éªŒæ€§åŠŸèƒ½
        - ä¸è®¾ç½®æ­¤é¡¹åˆ™ä¸å¼€å¯åˆè½´ï¼Œé»˜è®¤ä¸å¼€å¯åˆè½´ï¼Œè®¾ç½®æ­¤é¡¹åˆ™å¼€å¯åˆè½´
