# MindIE-LLM 支持模型列表

## 文本生成模型

---

| 模型                          | Support | 模型简介                                                     | README 链接                                                  | Hugging Face 链接                                            |
| :---------------------------- | :------ | :----------------------------------------------------------- | :----------------------------------------------------------- | :----------------------------------------------------------- |
| **DeepSeek 系列**             |         |                                                              |                                                              |                                                              |
| DeepSeek-R1-Distill-Llama-70B | <span style="color:green">●</span> | 利用 DeepSeek-R1 生成数据微调 Llama3-70B，性能卓越。         | [链接](https://gitcode.com/Ascend/MindIE-LLM/blob/master/examples/atb_models/examples/models/deepseek-r1-distill/DeepSeek-R1-Distill-Llama-70B.md) | [链接](https://huggingface.co/deepseek-ai/DeepSeek-R1-Distill-Llama-70B) |
| DeepSeek-R1-Distill-Llama-8B  | <span style="color: #FFA500;">●</span> | 利用 DeepSeek-R1 生成数据微调 Llama3-8B，小型稠密模型在多项基准中表现优异。 | [链接](https://gitcode.com/Ascend/MindIE-LLM/blob/master/examples/atb_models/examples/models/deepseek-r1-distill/DeepSeek-R1-Distill-Llama-8B.md) | [链接](https://huggingface.co/deepseek-ai/DeepSeek-R1-Distill-Llama-8B) |
| DeepSeek-R1-Distill-Qwen-14B  |         | 基于 DeepSeek-R1 数据微调 Qwen2.5-14B，提升推理与泛化能力。  | [链接](https://gitcode.com/Ascend/MindIE-LLM/blob/master/examples/atb_models/examples/models/deepseek-r1-distill/DeepSeek-R1-Distill-Qwen-14B.md) | [链接](https://huggingface.co/deepseek-ai/DeepSeek-R1-Distill-Qwen-14B) |
| DeepSeek-R1-Distill-Qwen-32B  |         | 基于 DeepSeek-R1 数据微调 Qwen2.5-32B，适合高精度任务。      | [链接](https://gitcode.com/Ascend/MindIE-LLM/blob/master/examples/atb_models/examples/models/deepseek-r1-distill/DeepSeek-R1-Distill-Qwen-32B.md) | [链接](https://huggingface.co/deepseek-ai/DeepSeek-R1-Distill-Qwen-32B) |
| DeepSeek-R1-Distill-Qwen-1.5B |         | 轻量级微调版 Qwen2.5-1.5B，适合端侧部署。                    | [链接](https://gitcode.com/Ascend/MindIE-LLM/blob/master/examples/atb_models/examples/models/deepseek-r1-distill/README_DeepSeek-R1-Distill-Qwen-1.5B.md) | [链接](https://huggingface.co/deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B) |
| DeepSeek-R1-Distill-Qwen-7B   |         | 微调版 Qwen2.5-7B，兼顾性能与效率。                          | [链接](https://gitcode.com/Ascend/MindIE-LLM/blob/master/examples/atb_models/examples/models/deepseek-r1-distill/README_DeepSeek-R1-Distill-Qwen-7B.md) | [链接](https://huggingface.co/deepseek-ai/DeepSeek-R1-Distill-Qwen-7B) |
| DeepSeek-MoE-16B-Chat         |         | 16B 混合专家模型，采用专家细分与共享策略，以更低计算成本达到 Llama2-7B 水平。 | [链接](https://gitcode.com/Ascend/MindIE-LLM/blob/master/examples/atb_models/examples/models/deepseek/README_deepseek_moe.md) | [链接](https://huggingface.co/deepseek-ai/deepseek-moe-16b-chat) |
| DeepSeek-V2-Chat-236B         |         | 基于 MLA 与 MoE 架构的高效大模型，支持 236B 总参数，推理高效、训练经济。 | [链接](https://gitcode.com/Ascend/MindIE-LLM/blob/master/examples/atb_models/examples/models/deepseekv2/README.md) | [链接](https://huggingface.co/deepseek-ai/DeepSeek-V2-Chat) |
| DeepSeek-V3-0324              |         | DeepSeek 高性能MoE模型，支持复杂推理与多语言任务。          | [链接](https://gitcode.com/Ascend/MindIE-LLM/blob/master/examples/atb_models/examples/models/deepseek-v3/README.md) | [链接](https://huggingface.co/deepseek-ai/DeepSeek-V3-0324) |
| DeepSeek-R1-0528              |         | DeepSeek MoE模型，能够生成高质量推理链。                  | [链接](https://gitcode.com/Ascend/MindIE-LLM/blob/master/examples/atb_models/examples/models/deepseek-r1/README.md) | [链接](https://huggingface.co/deepseek-ai/DeepSeek-R1-0528) |
| DeepSeek-V3.1                 |         | DeepSeek MoE模型，支持思考与非思考模式。                    | [链接](https://gitcode.com/Ascend/MindIE-LLM/blob/master/examples/atb_models/examples/models/deepseek-v3/README.md) | [链接](https://huggingface.co/deepseek-ai/DeepSeek-V3.1) |
| DeepSeek-V3.1-Terminus        |         | DeepSeek-V3.1最终版本，模型能力进一步提升。                 | [链接](https://gitcode.com/Ascend/MindIE-LLM/blob/master/examples/atb_models/examples/models/deepseek-v3/README.md) | [链接](https://huggingface.co/deepseek-ai/DeepSeek-V3.1-Terminus) |
| **Qwen 系列**                 |         |                                                              |                                                              |                                                              |
| Qwen2-7B                      |         | 阿里 Qwen2 系列基础模型，7B 规模，支持多语言与高效推理。     | [链接](https://gitcode.com/Ascend/MindIE-LLM/blob/master/examples/atb_models/examples/models/qwen/README.md) | [链接](https://huggingface.co/Qwen/Qwen2-7B) |
| Qwen2-72B                     |         | Qwen2 系列最大稠密模型，72B 参数，适用于高复杂度任务。       | [链接](https://gitcode.com/Ascend/MindIE-LLM/blob/master/examples/atb_models/examples/models/qwen/README.md) | [链接](https://huggingface.co/Qwen/Qwen2-72B) |
| Qwen2.5-0.5B                  |         | Qwen2.5 超轻量模型，适合极低资源设备部署。                   | [链接](https://gitcode.com/Ascend/MindIE-LLM/blob/master/examples/atb_models/examples/models/qwen/README.md) | [链接](https://huggingface.co/Qwen/Qwen2.5-0.5B) |
| Qwen2.5-1.5B                  |         | Qwen2.5 轻量主力模型，平衡性能与效率。                       | [链接](https://gitcode.com/Ascend/MindIE-LLM/blob/master/examples/atb_models/examples/models/qwen/README.md) | [链接](https://huggingface.co/Qwen/Qwen2.5-1.5B) |
| Qwen2.5-7B                    |         | Qwen2.5 主力模型，广泛用于通用与专业场景。                   | [链接](https://gitcode.com/Ascend/MindIE-LLM/blob/master/examples/atb_models/examples/models/qwen/README.md) | [链接](https://huggingface.co/Qwen/Qwen2.5-7B) |
| Qwen2.5-14B                   |         | Qwen2.5 中等规模模型，适合高精度推理。                       | [链接](https://gitcode.com/Ascend/MindIE-LLM/blob/master/examples/atb_models/examples/models/qwen/README.md) | [链接](https://huggingface.co/Qwen/Qwen2.5-14B) |
| Qwen2.5-32B                   |         | Qwen2.5 高性能版本，适用于企业级应用。                       | [链接](https://gitcode.com/Ascend/MindIE-LLM/blob/master/examples/atb_models/examples/models/qwen/README.md) | [链接](https://huggingface.co/Qwen/Qwen2.5-32B) |
| Qwen2.5-72B                   |         | Qwen2.5 最大稠密模型，72B 参数，支持复杂任务。               | [链接](https://gitcode.com/Ascend/MindIE-LLM/blob/master/examples/atb_models/examples/models/qwen/README.md) | [链接](https://huggingface.co/Qwen/Qwen2.5-72B) |
| QwenCode2.5-7B                |         | Qwen2.5 代码专用模型，7B 规模，优化代码生成与理解。          | [链接](https://gitcode.com/Ascend/MindIE-LLM/blob/master/examples/atb_models/examples/models/qwen/README.md) | [链接](https://huggingface.co/Qwen/Qwen2.5-Coder-7B-Instruct) |
| QwenCode2.5-32B               |         | Qwen2.5 高性能代码模型，32B 规模，适合专业开发场景。         | [链接](https://gitcode.com/Ascend/MindIE-LLM/blob/master/examples/atb_models/examples/models/qwen/README.md) | [链接](https://huggingface.co/Qwen/Qwen2.5-Coder-32B-Instruct) |
| Qwen3-32B                     |         | Qwen3 系列 32B 模型，新一代架构，更强推理与多语言能力。      | [链接](https://gitcode.com/Ascend/MindIE-LLM/blob/master/examples/atb_models/examples/models/qwen/README.md) | [链接](https://huggingface.co/Qwen/Qwen3-32B) |
| Qwen3-14B                     |         | Qwen3 中等规模高效模型。                                     | [链接](https://gitcode.com/Ascend/MindIE-LLM/blob/master/examples/atb_models/examples/models/qwen/README.md) | [链接](https://huggingface.co/Qwen/Qwen3-14B) |
| Qwen3-8B                      |         | Qwen3 轻量主力模型，适合通用部署。                           | [链接](https://gitcode.com/Ascend/MindIE-LLM/blob/master/examples/atb_models/examples/models/qwen/README.md) | [链接](https://huggingface.co/Qwen/Qwen3-8B) |
| Qwen3-4B                      |         | Qwen3 超轻量模型，端侧友好。                                 | [链接](https://gitcode.com/Ascend/MindIE-LLM/blob/master/examples/atb_models/examples/models/qwen/README.md) | [链接](https://huggingface.co/Qwen/Qwen3-4B) |
| Qwen3-30B-A3B                 |         | Qwen3 MoE 模型，总参数30B，激活参数3B，高效推理。             | [链接](https://gitcode.com/Ascend/MindIE-LLM/blob/master/examples/atb_models/examples/models/qwen/README.md) | [链接](https://huggingface.co/Qwen/Qwen3-30B-A3B) |
| Qwen3-30B-A3B-Instruct-2507   |         | Qwen3-30B-A3B非思考模式25年7月更新版本。                 | [链接](https://gitcode.com/Ascend/MindIE-LLM/blob/master/examples/atb_models/examples/models/qwen/README.md) | [链接](https://huggingface.co/Qwen/Qwen3-30B-A3B-Instruct-2507) |
| Qwen3-30B-A3B-Thinking-2507   |         | Qwen3-30B-A3B 25年7月更新版本。                        | [链接](https://gitcode.com/Ascend/MindIE-LLM/blob/master/examples/atb_models/examples/models/qwen/README.md) | [链接](https://huggingface.co/Qwen/Qwen3-235B-A22B-Thinking-2507) |
| Qwen3-235B-A22B               |         | Qwen3 超大规模 MoE 模型，总参数235B，激活参数22B，适用于前沿研究与高负载服务。 | [链接](https://gitcode.com/Ascend/MindIE-LLM/blob/master/examples/atb_models/examples/models/qwen/README.md) | [链接](https://huggingface.co/Qwen/Qwen3-235B-A22B) |
| Qwen3-235B-A22B-Instruct-2507 |         | Qwen3-235B-A22B非思考模式25年7月更新版本。              | [链接](https://gitcode.com/Ascend/MindIE-LLM/blob/master/examples/atb_models/examples/models/qwen/README.md) | [链接](https://huggingface.co/Qwen/Qwen3-235B-A22B-Instruct-2507) |
| Qwen3-235B-A22B-Thinking-2507 |         | Qwen3-235B-A22B 25年7月更新版本。                     | [链接](https://gitcode.com/Ascend/MindIE-LLM/blob/master/examples/atb_models/examples/models/qwen/README.md) | [链接](https://huggingface.co/Qwen/Qwen3-235B-A22B-Thinking-2507) |
| Qwen3-Coder-30B-A3B-Instruct   |         | 针对代码生成任务的Qwen3 MoE 模型，总参数30B，激活参数3B。  | [链接](https://gitcode.com/Ascend/MindIE-LLM/blob/master/examples/atb_models/examples/models/qwen/README.md) | [链接](https://huggingface.co/Qwen/Qwen3-Coder-30B-A3B-Instruct) |
| Qwen3-Coder-480B-A35B-Instruct |         | 针对代码生成任务的Qwen3 MoE 模型，总参数480B，激活参数35B。 | [链接](https://gitcode.com/Ascend/MindIE-LLM/blob/master/examples/atb_models/examples/models/qwen/README.md) | [链接](https://huggingface.co/Qwen/Qwen3-Coder-480B-A35B-Instruct) |
| **ERNIE 系列**                |         |                                                              |                                                              |                                                              |
| ERNIE-4.5-300B-A47B           |         | 文心4.5系列MoE模型，总参数300B，激活参数47B。                | [链接](https://gitcode.com/Ascend/MindIE-LLM/blob/master/examples/atb_models/examples/models/ernie_moe/README.md) | [链接](https://huggingface.co/baidu/ERNIE-4.5-300B-A47B-PT) |
| **KIMI 系列**                 |         |                                                              |                                                              |                                                              |
| Kimi-K2-Instruct              |         | Kimi K2系列MoE模型，总参数1000B，激活参数32B。               | [链接](https://gitcode.com/Ascend/MindIE-LLM/blob/master/examples/atb_models/examples/models/kimi_k2/README.md) | [链接](https://huggingface.co/moonshotai/Kimi-K2-Instruct) |
| Kimi-K2-Thinking              |         | Kimi K2系列MoE模型，支持思考链，总参数1000B，激活参数32B。   | [链接](https://gitcode.com/Ascend/MindIE-LLM/blob/master/examples/atb_models/examples/models/kimi_k2/README.md) | [链接](https://huggingface.co/moonshotai/Kimi-K2-Thinking) |
| **GLM 系列**                  |         |                                                              |                                                              |                                                              |
| GLM-4.5                       |         | GLM 4.5系列MoE模型，总参数355B，激活参数32B。                | [链接](https://gitcode.com/Ascend/MindIE-LLM/blob/master/examples/atb_models/examples/models/glm/README.md) | [链接](https://huggingface.co/zai-org/GLM-4.5) |

---

### 图例说明：
- **<span style="color:green">●</span>**：经过充分验证支持（功能完整、精度达标、性能稳定）
- **<span style="color: #FFA500;">●</span>**：仅功能支持（可运行，但未充分验证或存在已知限制）
