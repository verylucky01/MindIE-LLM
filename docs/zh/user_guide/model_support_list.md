

| 模型                          | 模型简介                                                     | README 链接                                                  | Hugging Face 链接                                            |
| :---------------------------- | :----------------------------------------------------------- | :----------------------------------------------------------- | :----------------------------------------------------------- |
| **DeepSeek 系列**             |                                                              |                                                              |                                                          |
| DeepSeek-R1-Distill-Llama-70B | 利用 DeepSeek-R1 生成数据微调 Llama3-70B，性能卓越。         | [链接](https://gitcode.com/Ascend/MindIE-LLM/blob/master/examples/atb_models/examples/models/deepseek-r1-distill/DeepSeek-R1-Distill-Llama-70B.md  ) | [链接](https://huggingface.co/deepseek-ai/DeepSeek-R1-Distill-Llama-70B  ) |
| DeepSeek-R1-Distill-Llama-8B  | 利用 DeepSeek-R1 生成数据微调 Llama3-8B，小型稠密模型在多项基准中表现优异。 | [链接](https://gitcode.com/Ascend/MindIE-LLM/blob/master/examples/atb_models/examples/models/deepseek-r1-distill/DeepSeek-R1-Distill-Llama-8B.md  ) | [链接](https://huggingface.co/deepseek-ai/DeepSeek-R1-Distill-Llama-8B  ) |
| DeepSeek-R1-Distill-Qwen-14B  | 基于 DeepSeek-R1 数据微调 Qwen2.5-14B，提升推理与泛化能力。  | [链接](https://gitcode.com/Ascend/MindIE-LLM/blob/master/examples/atb_models/examples/models/deepseek-r1-distill/DeepSeek-R1-Distill-Qwen-14B.md  ) | [链接](https://huggingface.co/deepseek-ai/DeepSeek-R1-Distill-Qwen-14B  ) |
| DeepSeek-R1-Distill-Qwen-32B  | 基于 DeepSeek-R1 数据微调 Qwen2.5-32B，适合高精度任务。      | [链接](https://gitcode.com/Ascend/MindIE-LLM/blob/master/examples/atb_models/examples/models/deepseek-r1-distill/DeepSeek-R1-Distill-Qwen-32B.md  ) | [链接](https://huggingface.co/deepseek-ai/DeepSeek-R1-Distill-Qwen-32B  ) |
| DeepSeek-R1-Distill-Qwen-1.5B | 轻量级微调版 Qwen2.5-1.5B，适合端侧部署。                    | [链接](https://gitcode.com/Ascend/MindIE-LLM/blob/master/examples/atb_models/examples/models/deepseek-r1-distill/README_DeepSeek-R1-Distill-Qwen-1.5B.md  ) | [链接](https://huggingface.co/deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B  ) |
| DeepSeek-R1-Distill-Qwen-7B   | 微调版 Qwen2.5-7B，兼顾性能与效率。                          | [链接](https://gitcode.com/Ascend/MindIE-LLM/blob/master/examples/atb_models/examples/models/deepseek-r1-distill/README_DeepSeek-R1-Distill-Qwen-7B.md  ) | [链接](https://huggingface.co/deepseek-ai/DeepSeek-R1-Distill-Qwen-7B  ) |
| DeepSeek-MoE-16B-Chat         | 16B 混合专家模型，采用专家细分与共享策略，以更低计算成本达到 Llama2-7B 水平。 | [链接](https://gitcode.com/Ascend/MindIE-LLM/blob/master/examples/atb_models/examples/models/deepseek/README_deepseek_moe.md  ) | [链接](https://huggingface.co/deepseek-ai/deepseek-moe-16b-chat  ) |
| DeepSeek-V2-Chat-236B         | 基于 MLA 与 MoE 架构的高效大模型，支持 236B 总参数，推理高效、训练经济。 | [链接](https://gitcode.com/Ascend/MindIE-LLM/blob/master/examples/atb_models/examples/models/deepseekv2/README.md  ) | [链接](https://huggingface.co/deepseek-ai/DeepSeek-V2-Chat  )  |
| DeepSeek-V3-0324              | DeepSeek 高性能MoE模型，支持复杂推理与多语言任务。          | [链接](https://gitcode.com/Ascend/MindIE-LLM/blob/master/examples/atb_models/examples/models/deepseek-v3/README.md) | [链接](https://huggingface.co/deepseek-ai/DeepSeek-V3-0324)  |
| DeepSeek-R1-0528              | DeepSeek MoE模型，能够生成高质量推理链。                  | [链接](https://gitcode.com/Ascend/MindIE-LLM/blob/master/examples/atb_models/examples/models/deepseek-r1/README.md) | [链接](https://huggingface.co/deepseek-ai/DeepSeek-R1-0528)  |
| DeepSeek-V3.1                 | DeepSeek MoE模型，支持思考与非思考模式。                    | [链接](https://gitcode.com/Ascend/MindIE-LLM/blob/master/examples/atb_models/examples/models/deepseek-v3/README.md) | [链接](hhttps://huggingface.co/deepseek-ai/DeepSeek-V3.1)  |
| DeepSeek-V3.1-Terminus        | DeepSeek-V3.1最终版本，模型能力进一步提升。                 | [链接](https://gitcode.com/Ascend/MindIE-LLM/blob/master/examples/atb_models/examples/models/deepseek-v3/README.md) | [链接](https://huggingface.co/deepseek-ai/DeepSeek-V3.1-Terminus)  |
| **Qwen 系列**                 |                                                              |                                                              |                                                              |
| Qwen2-7B                      | 阿里 Qwen2 系列基础模型，7B 规模，支持多语言与高效推理。     | [链接](https://gitcode.com/Ascend/MindIE-LLM/blob/master/examples/atb_models/examples/models/qwen/README.md  ) | [链接](https://huggingface.co/Qwen/Qwen2-7B  )                 |
| Qwen2-72B                     | Qwen2 系列最大稠密模型，72B 参数，适用于高复杂度任务。       | [链接](https://gitcode.com/Ascend/MindIE-LLM/blob/master/examples/atb_models/examples/models/qwen/README.md  ) | [链接](https://huggingface.co/Qwen/Qwen2-72B  )                |
| gte-Qwen2-7B                  | 基于 Qwen2-7B 的通用文本嵌入模型，用于高质量语义向量表示。   | [链接](https://gitcode.com/Ascend/MindIE-LLM/blob/master/examples/atb_models/examples/models/qwen/README.md  ) | [链接](https://huggingface.co/Qwen/gte-Qwen2-7B  )             |
| Qwen2.5-0.5B                  | Qwen2.5 超轻量模型，适合极低资源设备部署。                   | [链接](https://gitcode.com/Ascend/MindIE-LLM/blob/master/examples/atb_models/examples/models/qwen/README.md  ) | [链接](https://huggingface.co/Qwen/Qwen2.5-0.5B  )             |
| Qwen2.5-1.5B                  | Qwen2.5 轻量主力模型，平衡性能与效率。                       | [链接](https://gitcode.com/Ascend/MindIE-LLM/blob/master/examples/atb_models/examples/models/qwen/README.md  ) | [链接](https://huggingface.co/Qwen/Qwen2.5-1.5B  )             |
| Qwen2.5-7B                    | Qwen2.5 主力模型，广泛用于通用与专业场景。                   | [链接](https://gitcode.com/Ascend/MindIE-LLM/blob/master/examples/atb_models/examples/models/qwen/README.md  ) | [链接](https://huggingface.co/Qwen/Qwen2.5-7B  )               |
| Qwen2.5-14B                   | Qwen2.5 中等规模模型，适合高精度推理。                       | [链接](https://gitcode.com/Ascend/MindIE-LLM/blob/master/examples/atb_models/examples/models/qwen/README.md  ) | [链接](https://huggingface.co/Qwen/Qwen2.5-14B  )              |
| Qwen2.5-32B                   | Qwen2.5 高性能版本，适用于企业级应用。                       | [链接](https://gitcode.com/Ascend/MindIE-LLM/blob/master/examples/atb_models/examples/models/qwen/README.md  ) | [链接](https://huggingface.co/Qwen/Qwen2.5-32B  )              |
| Qwen2.5-72B                   | Qwen2.5 最大稠密模型，72B 参数，支持复杂任务。               | [链接](https://gitcode.com/Ascend/MindIE-LLM/blob/master/examples/atb_models/examples/models/qwen/README.md  ) | [链接](https://huggingface.co/Qwen/Qwen2.5-72B  )              |
| QwenCode2.5-7B                | Qwen2.5 代码专用模型，7B 规模，优化代码生成与理解。          | [链接](https://gitcode.com/Ascend/MindIE-LLM/blob/master/examples/atb_models/examples/models/qwen/README.md  ) | [链接](https://huggingface.co/Qwen/Qwen2.5-Coder-7B-Instruct  ) |
| QwenCode2.5-32B               | Qwen2.5 高性能代码模型，32B 规模，适合专业开发场景。         | [链接](https://gitcode.com/Ascend/MindIE-LLM/blob/master/examples/atb_models/examples/models/qwen/README.md  ) | [链接](https://huggingface.co/Qwen/Qwen2.5-Coder-32B-Instruct  ) |
| Qwen3-32B                     | Qwen3 系列 32B 模型，新一代架构，更强推理与多语言能力。      | [链接](https://gitcode.com/Ascend/MindIE-LLM/blob/master/examples/atb_models/examples/models/qwen/README.md  ) | [链接](https://huggingface.co/Qwen/Qwen3-32B  )                |
| Qwen3-14B                     | Qwen3 中等规模高效模型。                                     | [链接](https://gitcode.com/Ascend/MindIE-LLM/blob/master/examples/atb_models/examples/models/qwen/README.md  ) | [链接](https://huggingface.co/Qwen/Qwen3-14B  )                |
| Qwen3-8B                      | Qwen3 轻量主力模型，适合通用部署。                           | [链接](https://gitcode.com/Ascend/MindIE-LLM/blob/master/examples/atb_models/examples/models/qwen/README.md  ) | [链接](https://huggingface.co/Qwen/Qwen3-8B  )                 |
| Qwen3-4B                      | Qwen3 超轻量模型，端侧友好。                                 | [链接](https://gitcode.com/Ascend/MindIE-LLM/blob/master/examples/atb_models/examples/models/qwen/README.md  ) | [链接](https://huggingface.co/Qwen/Qwen3-4B  )                 |
| Qwen2-Audio-7B-Instruct       | 多模态音频语言模型，可识别情绪、音乐类型、环境声，支持混合音频理解与文本回复。 | [链接](https://gitcode.com/Ascend/MindIE-LLM/blob/master/examples/atb_models/examples/models/qwen2_audio/README.md  ) | [链接](https://huggingface.co/Qwen/Qwen2-Audio-7B-Instruct  )  |
| Qwen2-VL-2B-Instruct          | Qwen2-VL 轻量多模态模型，2B 规模，支持图文对话。             | [链接](https://gitcode.com/Ascend/MindIE-LLM/blob/master/examples/atb_models/examples/models/qwen2_vl/README.md  ) | [链接](https://huggingface.co/Qwen/Qwen2-VL-2B-Instruct  )     |
| Qwen2-VL-2B                   | Qwen2-VL 基础版，2B 规模，无指令微调。                       | [链接](https://gitcode.com/Ascend/MindIE-LLM/blob/master/examples/atb_models/examples/models/qwen2_vl/README.md  ) | [链接](https://huggingface.co/Qwen/Qwen2-VL-2B  )              |
| Qwen2-VL-7B-Instruct          | Qwen2-VL 主力多模态模型，7B 规模，指令微调版。               | [链接](https://gitcode.com/Ascend/MindIE-LLM/blob/master/examples/atb_models/examples/models/qwen2_vl/README.md  ) | [链接](https://huggingface.co/Qwen/Qwen2-VL-7B-Instruct  )     |
| Qwen2-VL-7B                   | Qwen2-VL 7B 基础版。                                         | [链接](https://gitcode.com/Ascend/MindIE-LLM/blob/master/examples/atb_models/examples/models/qwen2_vl/README.md  ) | [链接](https://huggingface.co/Qwen/Qwen2-VL-7B  )              |
| Qwen2-VL-72B-Instruct         | Qwen2-VL 最大版本，72B 规模，支持高精度视觉理解。            | [链接](https://gitcode.com/Ascend/MindIE-LLM/blob/master/examples/atb_models/examples/models/qwen2_vl/README.md  ) | [链接](https://huggingface.co/Qwen/Qwen2-VL-72B-Instruct  )    |
| Qwen2-VL-72B                  | Qwen2-VL 72B 基础版。                                        | [链接](https://gitcode.com/Ascend/MindIE-LLM/blob/master/examples/atb_models/examples/models/qwen2_vl/README.md  ) | [链接](https://huggingface.co/Qwen/Qwen2-VL-72B  )             |
| QVQ-72B-Preview               | Qwen 多模态推理模型预览版，72B 规模，支持视觉问答与复杂推理。 | [链接](https://gitcode.com/Ascend/MindIE-LLM/blob/master/examples/atb_models/examples/models/qwen2_vl/README.md  ) | [链接](https://huggingface.co/Qwen/QVQ-72B-Preview  )          |
| Qwen2.5-VL-3B-Instruct        | Qwen2.5-VL 轻量多模态模型，3B 规模，指令微调。               | [链接](https://gitcode.com/Ascend/MindIE-LLM/blob/master/examples/atb_models/examples/models/qwen2_vl/README.md  ) | [链接](https://huggingface.co/Qwen/Qwen2.5-VL-3B-Instruct  )   |
| Qwen2.5-VL-7B-Instruct        | Qwen2.5-VL 主力多模态模型，7B 规模。                         | [链接](https://gitcode.com/Ascend/MindIE-LLM/blob/master/examples/atb_models/examples/models/qwen2_vl/README.md  ) | [链接](https://huggingface.co/Qwen/Qwen2.5-VL-7B-Instruct  )   |
| Qwen2.5-VL-32B-Instruct       | Qwen2.5-VL 高性能多模态模型，32B 规模。                      | [链接](https://gitcode.com/Ascend/MindIE-LLM/blob/master/examples/atb_models/examples/models/qwen2_vl/README.md  ) | [链接](https://huggingface.co/Qwen/Qwen2.5-VL-32B-Instruct  )  |
| Qwen2.5-VL-72B-Instruct       | Qwen2.5-VL 最大版本，72B 规模，支持高分辨率图像理解。        | [链接](https://gitcode.com/Ascend/MindIE-LLM/blob/master/examples/atb_models/examples/models/qwen2_vl/README.md  ) | [链接](https://huggingface.co/Qwen/Qwen2.5-VL-72B-Instruct  )  |
| Qwen3-30B-A3B                 | Qwen3 MoE 模型，总参数30B，激活参数3B，高效推理。             | [链接](https://gitcode.com/Ascend/MindIE-LLM/blob/master/examples/atb_models/examples/models/qwen/README.md) | [链接](https://huggingface.co/Qwen/Qwen3-30B-A3B)            |
| Qwen3-30B-A3B-Instruct-2507   | Qwen3-30B-A3B非思考模式25年7月更新版本。                 | [链接](https://gitcode.com/Ascend/MindIE-LLM/blob/master/examples/atb_models/examples/models/qwen/README.md) | [链接](https://huggingface.co/Qwen/Qwen3-30B-A3B-Instruct-2507)         |
| Qwen3-30B-A3B-Thinking-2507   | Qwen3-30B-A3B 25年7月更新版本。                        | [链接](https://gitcode.com/Ascend/MindIE-LLM/blob/master/examples/atb_models/examples/models/qwen/README.md) | [链接](https://huggingface.co/Qwen/Qwen3-235B-A22B-Thinking-2507)      |
| Qwen3-235B-A22B               | Qwen3 超大规模 MoE 模型，总参数235B，激活参数22B，适用于前沿研究与高负载服务。 | [链接](https://gitcode.com/Ascend/MindIE-LLM/blob/master/examples/atb_models/examples/models/qwen/README.md) | [链接](https://huggingface.co/Qwen/Qwen3-235B-A22B)     |
| Qwen3-235B-A22B-Instruct-2507 | Qwen3-235B-A22B非思考模式25年7月更新版本。              | [链接](https://gitcode.com/Ascend/MindIE-LLM/blob/master/examples/atb_models/examples/models/qwen/README.md) | [链接](https://huggingface.co/Qwen/Qwen3-235B-A22B-Instruct-2507)  |
| Qwen3-235B-A22B-Thinking-2507 | Qwen3-235B-A22B 25年7月更新版本。                     | [链接](https://gitcode.com/Ascend/MindIE-LLM/blob/master/examples/atb_models/examples/models/qwen/README.md) | [链接](https://huggingface.co/Qwen/Qwen3-235B-A22B-Thinking-2507)  |
| Qwen3-Coder-30B-A3B-Instruct   | 针对代码生成任务的Qwen3 MoE 模型，总参数30B，激活参数3B。  | [链接](https://gitcode.com/Ascend/MindIE-LLM/blob/master/examples/atb_models/examples/models/qwen/README.md) | [链接](https://huggingface.co/Qwen/Qwen3-Coder-30B-A3B-Instruct)   |
| Qwen3-Coder-480B-A35B-Instruct | 针对代码生成任务的Qwen3 MoE 模型，总参数480B，激活参数35B。 | [链接](https://gitcode.com/Ascend/MindIE-LLM/blob/master/examples/atb_models/examples/models/qwen/README.md) | [链接](https://huggingface.co/Qwen/Qwen3-Coder-480B-A35B-Instruct)   |
| **ERNIE 系列**             |                                                              |                                                              |                                                              |
| ERNIE-4.5-300B-A47B           | 文心4.5系列MoE模型，总参数300B，激活参数47B。      | [链接](https://gitcode.com/Ascend/MindIE-LLM/blob/master/examples/atb_models/examples/models/ernie_moe/README.md) | [链接](https://huggingface.co/baidu/ERNIE-4.5-300B-A47B-PT)   |
| **KIMI 系列**             |                                                              |                                                              |                                                              |
| Kimi-K2-Instruct              | Kimi K2系列MoE模型，总参数1000B，激活参数32B。      | [链接](https://gitcode.com/Ascend/MindIE-LLM/blob/master/examples/atb_models/examples/models/kimi_k2/README.md) | [链接](https://huggingface.co/moonshotai/Kimi-K2-Instruct)   |
| Kimi-K2-Thinking              | Kimi K2系列MoE模型，支持思考链，总参数1000B，激活参数32B。  | [链接](https://gitcode.com/Ascend/MindIE-LLM/blob/master/examples/atb_models/examples/models/kimi_k2/README.md) | [链接](https://huggingface.co/moonshotai/Kimi-K2-Thinking)   |
| **GLM 系列**             |                                                              |                                                              |                                                              |
| GLM-4.5                       | GLM 4.5系列MoE模型，总参数355B，激活参数32B。      | [链接](https://gitcode.com/Ascend/MindIE-LLM/blob/master/examples/atb_models/examples/models/glm/README.md) | [链接](https://huggingface.co/zai-org/GLM-4.5)   |
